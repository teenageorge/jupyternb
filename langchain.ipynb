{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T13:35:02.920065Z",
     "start_time": "2024-06-14T13:34:49.547927Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "%pip install langchain_core"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_core\r\n",
      "  Downloading langchain_core-0.2.6-py3-none-any.whl.metadata (5.8 kB)\r\n",
      "Collecting langchain_anthropic\r\n",
      "  Downloading langchain_anthropic-0.1.15-py3-none-any.whl.metadata (2.1 kB)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from langchain_core) (6.0.1)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from langchain_core) (1.33)\r\n",
      "Collecting langsmith<0.2.0,>=0.1.75 (from langchain_core)\r\n",
      "  Downloading langsmith-0.1.77-py3-none-any.whl.metadata (13 kB)\r\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from langchain_core) (23.2)\r\n",
      "Collecting pydantic<3,>=1 (from langchain_core)\r\n",
      "  Downloading pydantic-2.7.4-py3-none-any.whl.metadata (109 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m109.4/109.4 kB\u001B[0m \u001B[31m2.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting tenacity<9.0.0,>=8.1.0 (from langchain_core)\r\n",
      "  Downloading tenacity-8.3.0-py3-none-any.whl.metadata (1.2 kB)\r\n",
      "Collecting anthropic<1,>=0.28.0 (from langchain_anthropic)\r\n",
      "  Downloading anthropic-0.28.0-py3-none-any.whl.metadata (18 kB)\r\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from langchain_anthropic) (0.7.1)\r\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from anthropic<1,>=0.28.0->langchain_anthropic) (4.2.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from anthropic<1,>=0.28.0->langchain_anthropic) (1.8.0)\r\n",
      "Collecting httpx<1,>=0.23.0 (from anthropic<1,>=0.28.0->langchain_anthropic)\r\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\r\n",
      "Collecting jiter<1,>=0.4.0 (from anthropic<1,>=0.28.0->langchain_anthropic)\r\n",
      "  Downloading jiter-0.4.2-cp312-cp312-macosx_10_12_x86_64.whl.metadata (3.6 kB)\r\n",
      "Requirement already satisfied: sniffio in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from anthropic<1,>=0.28.0->langchain_anthropic) (1.3.0)\r\n",
      "Collecting tokenizers>=0.13.0 (from anthropic<1,>=0.28.0->langchain_anthropic)\r\n",
      "  Downloading tokenizers-0.19.1-cp312-cp312-macosx_10_12_x86_64.whl.metadata (6.7 kB)\r\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from anthropic<1,>=0.28.0->langchain_anthropic) (4.11.0)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain_core) (2.1)\r\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.75->langchain_core)\r\n",
      "  Downloading orjson-3.10.5-cp312-cp312-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (49 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m49.7/49.7 kB\u001B[0m \u001B[31m1.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: requests<3,>=2 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.75->langchain_core) (2.31.0)\r\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1->langchain_core)\r\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\r\n",
      "Collecting pydantic-core==2.18.4 (from pydantic<3,>=1->langchain_core)\r\n",
      "  Downloading pydantic_core-2.18.4-cp312-cp312-macosx_10_12_x86_64.whl.metadata (6.5 kB)\r\n",
      "Requirement already satisfied: idna>=2.8 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from anyio<5,>=3.5.0->anthropic<1,>=0.28.0->langchain_anthropic) (3.4)\r\n",
      "Requirement already satisfied: certifi in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->anthropic<1,>=0.28.0->langchain_anthropic) (2024.6.2)\r\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->anthropic<1,>=0.28.0->langchain_anthropic)\r\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\r\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->anthropic<1,>=0.28.0->langchain_anthropic)\r\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain_core) (2.0.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain_core) (2.1.0)\r\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from tokenizers>=0.13.0->anthropic<1,>=0.28.0->langchain_anthropic)\r\n",
      "  Downloading huggingface_hub-0.23.3-py3-none-any.whl.metadata (12 kB)\r\n",
      "Collecting filelock (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<1,>=0.28.0->langchain_anthropic)\r\n",
      "  Downloading filelock-3.15.1-py3-none-any.whl.metadata (2.8 kB)\r\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<1,>=0.28.0->langchain_anthropic)\r\n",
      "  Downloading fsspec-2024.6.0-py3-none-any.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<1,>=0.28.0->langchain_anthropic) (4.65.0)\r\n",
      "Downloading langchain_core-0.2.6-py3-none-any.whl (315 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m315.5/315.5 kB\u001B[0m \u001B[31m7.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0mta \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading langchain_anthropic-0.1.15-py3-none-any.whl (16 kB)\r\n",
      "Downloading anthropic-0.28.0-py3-none-any.whl (862 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m862.7/862.7 kB\u001B[0m \u001B[31m17.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading langsmith-0.1.77-py3-none-any.whl (125 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m125.2/125.2 kB\u001B[0m \u001B[31m4.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading pydantic-2.7.4-py3-none-any.whl (409 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m409.0/409.0 kB\u001B[0m \u001B[31m11.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading pydantic_core-2.18.4-cp312-cp312-macosx_10_12_x86_64.whl (1.8 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.8/1.8 MB\u001B[0m \u001B[31m31.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading tenacity-8.3.0-py3-none-any.whl (25 kB)\r\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\r\n",
      "Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m75.6/75.6 kB\u001B[0m \u001B[31m2.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m77.9/77.9 kB\u001B[0m \u001B[31m1.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0mta \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading jiter-0.4.2-cp312-cp312-macosx_10_12_x86_64.whl (303 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m303.4/303.4 kB\u001B[0m \u001B[31m10.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading orjson-3.10.5-cp312-cp312-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (258 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m258.9/258.9 kB\u001B[0m \u001B[31m8.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading tokenizers-0.19.1-cp312-cp312-macosx_10_12_x86_64.whl (2.5 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.5/2.5 MB\u001B[0m \u001B[31m42.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading huggingface_hub-0.23.3-py3-none-any.whl (401 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m401.7/401.7 kB\u001B[0m \u001B[31m11.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading fsspec-2024.6.0-py3-none-any.whl (176 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m176.9/176.9 kB\u001B[0m \u001B[31m6.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m58.3/58.3 kB\u001B[0m \u001B[31m1.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading filelock-3.15.1-py3-none-any.whl (15 kB)\r\n",
      "Installing collected packages: tenacity, pydantic-core, orjson, jiter, h11, fsspec, filelock, annotated-types, pydantic, huggingface-hub, httpcore, tokenizers, langsmith, httpx, langchain_core, anthropic, langchain_anthropic\r\n",
      "Successfully installed annotated-types-0.7.0 anthropic-0.28.0 filelock-3.15.1 fsspec-2024.6.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 huggingface-hub-0.23.3 jiter-0.4.2 langchain_anthropic-0.1.15 langchain_core-0.2.6 langsmith-0.1.77 orjson-3.10.5 pydantic-2.7.4 pydantic-core-2.18.4 tenacity-8.3.0 tokenizers-0.19.1\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T13:54:31.790770Z",
     "start_time": "2024-06-14T13:54:25.789784Z"
    }
   },
   "cell_type": "code",
   "source": "%pip install langchain_openai",
   "id": "55365d51ecfc3ad9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_openai\r\n",
      "  Downloading langchain_openai-0.1.8-py3-none-any.whl.metadata (2.5 kB)\r\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.2.2 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from langchain_openai) (0.2.6)\r\n",
      "Collecting openai<2.0.0,>=1.26.0 (from langchain_openai)\r\n",
      "  Downloading openai-1.34.0-py3-none-any.whl.metadata (21 kB)\r\n",
      "Collecting tiktoken<1,>=0.7 (from langchain_openai)\r\n",
      "  Downloading tiktoken-0.7.0-cp312-cp312-macosx_10_9_x86_64.whl.metadata (6.6 kB)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from langchain-core<0.3,>=0.2.2->langchain_openai) (6.0.1)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from langchain-core<0.3,>=0.2.2->langchain_openai) (1.33)\r\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from langchain-core<0.3,>=0.2.2->langchain_openai) (0.1.77)\r\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from langchain-core<0.3,>=0.2.2->langchain_openai) (23.2)\r\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from langchain-core<0.3,>=0.2.2->langchain_openai) (2.7.4)\r\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from langchain-core<0.3,>=0.2.2->langchain_openai) (8.3.0)\r\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (4.2.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (1.8.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (0.27.0)\r\n",
      "Requirement already satisfied: sniffio in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (1.3.0)\r\n",
      "Requirement already satisfied: tqdm>4 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (4.65.0)\r\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (4.11.0)\r\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain_openai)\r\n",
      "  Downloading regex-2024.5.15-cp312-cp312-macosx_10_9_x86_64.whl.metadata (40 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m40.9/40.9 kB\u001B[0m \u001B[31m1.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: requests>=2.26.0 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2.31.0)\r\n",
      "Requirement already satisfied: idna>=2.8 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.26.0->langchain_openai) (3.4)\r\n",
      "Requirement already satisfied: certifi in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain_openai) (2024.6.2)\r\n",
      "Requirement already satisfied: httpcore==1.* in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain_openai) (1.0.5)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain_openai) (0.14.0)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.2->langchain_openai) (2.1)\r\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.2->langchain_openai) (3.10.5)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.2->langchain_openai) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.2->langchain_openai) (2.18.4)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.0.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.1.0)\r\n",
      "Downloading langchain_openai-0.1.8-py3-none-any.whl (38 kB)\r\n",
      "Downloading openai-1.34.0-py3-none-any.whl (325 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m325.5/325.5 kB\u001B[0m \u001B[31m6.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading tiktoken-0.7.0-cp312-cp312-macosx_10_9_x86_64.whl (960 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m960.4/960.4 kB\u001B[0m \u001B[31m11.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading regex-2024.5.15-cp312-cp312-macosx_10_9_x86_64.whl (282 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m282.4/282.4 kB\u001B[0m \u001B[31m7.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: regex, tiktoken, openai, langchain_openai\r\n",
      "Successfully installed langchain_openai-0.1.8 openai-1.34.0 regex-2024.5.15 tiktoken-0.7.0\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T14:28:33.002645Z",
     "start_time": "2024-06-14T14:28:31.350223Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "chat_model = ChatOpenAI(\n",
    "    model=\"gpt-4\",\n",
    "    temperature=0.7,\n",
    "    api_key=\"API-KEY\"\n",
    ")"
   ],
   "id": "b58402e784870458",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T14:04:01.917177Z",
     "start_time": "2024-06-14T14:03:59.571067Z"
    }
   },
   "cell_type": "code",
   "source": "chat_model.invoke(\"Tell me a joke about bears!\")",
   "id": "228d0c64152e691a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Why don't bears wear shoes?\\n\\nBecause they prefer bear feet!\", response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 14, 'total_tokens': 27}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-4852b811-a7b3-47fc-9f10-39098761407b-0', usage_metadata={'input_tokens': 14, 'output_tokens': 13, 'total_tokens': 27})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T14:04:07.138218Z",
     "start_time": "2024-06-14T14:04:05.250226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "chat_model.invoke([\n",
    " HumanMessage(\"Tell me a joke about bears!\")       \n",
    "])"
   ],
   "id": "c86cbd2228008953",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Why don't bears wear shoes?\\n\\nBecause they prefer bear feet!\", response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 14, 'total_tokens': 27}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-ae57b49f-321a-4015-8906-a300954ca7f7-0', usage_metadata={'input_tokens': 14, 'output_tokens': 13, 'total_tokens': 27})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T14:07:07.681012Z",
     "start_time": "2024-06-14T14:07:07.677235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "joke_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a world class comedian.\"),\n",
    "    (\"human\", \"Tell me a joke about {topic}\")\n",
    "])"
   ],
   "id": "1643ef83d457299e",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T14:07:48.065222Z",
     "start_time": "2024-06-14T14:07:48.055789Z"
    }
   },
   "cell_type": "code",
   "source": "joke_prompt.invoke({\"topic\": \"beets\"})",
   "id": "8885640e81e897db",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a world class comedian.'), HumanMessage(content='Tell me a joke about beets')])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T14:08:39.188399Z",
     "start_time": "2024-06-14T14:08:39.185102Z"
    }
   },
   "cell_type": "code",
   "source": "chain = joke_prompt | chat_model",
   "id": "f396dc404ce40dcf",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T14:08:57.650291Z",
     "start_time": "2024-06-14T14:08:54.234945Z"
    }
   },
   "cell_type": "code",
   "source": "chain.invoke({\"topic\": \"beets\"})",
   "id": "6e506c94bd2b115b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Why did the beet blush?\\n\\nBecause it saw the salad dressing!', response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 25, 'total_tokens': 38}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-945f2d54-39a8-44af-a8d7-34c4b826965a-0', usage_metadata={'input_tokens': 25, 'output_tokens': 13, 'total_tokens': 38})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T14:10:35.340915Z",
     "start_time": "2024-06-14T14:10:32.073847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "str_chain = chain | StrOutputParser()\n",
    "str_chain.invoke({\"topic\": \"beets\"})"
   ],
   "id": "ef1057a36ab4539f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why did the beet turn red?\\n\\nBecause it saw the salad dressing!'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T14:14:16.323372Z",
     "start_time": "2024-06-14T14:14:13.933963Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for chunk in str_chain.stream({\"topic\": \"beets\"}):\n",
    "    print(chunk, end=\"|\")"
   ],
   "id": "7e2c18a285dfbdce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Why| did| the| beet| blush|?\n",
      "\n",
      "|Because| it| saw| the| salad| dressing|!||"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T14:14:09.692762Z",
     "start_time": "2024-06-14T14:14:06.806640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chunks = []\n",
    "async for chunk in str_chain.astream({\"topic\": \"beets\"}):\n",
    "    chunks.append(chunk)\n",
    "    print(chunk, end=\"|\", flush=True)\n",
    "    "
   ],
   "id": "de5b32a50e452782",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Why| did| the| beet| turn| red|?\n",
      "\n",
      "|Because| it| saw| the| salad| dressing|!||"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T14:15:17.100612Z",
     "start_time": "2024-06-14T14:15:14.321250Z"
    }
   },
   "cell_type": "code",
   "source": "chat_model.invoke(\"What is today's date?\")",
   "id": "3c3da9df878f8b75",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As an AI, I don't have real-time capabilities to provide the current date.\", response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 13, 'total_tokens': 30}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-bdc392a8-ae55-4629-8847-d6462a27cea2-0', usage_metadata={'input_tokens': 13, 'output_tokens': 17, 'total_tokens': 30})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T14:17:37.641935Z",
     "start_time": "2024-06-14T14:17:34.969607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datetime import date\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", 'You know that current date is \"{current_date}\"'),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "chain = prompt | chat_model | StrOutputParser()\n",
    "\n",
    "chain.invoke({\n",
    "    \"question\": \"What is today's date?\",\n",
    "    \"current_date\": date.today()\n",
    "})"
   ],
   "id": "be8053960723b71d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Today's date is June 14, 2024.\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T14:20:04.985425Z",
     "start_time": "2024-06-14T14:20:03.447102Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chain.invoke({\n",
    "    \"question\": \"What is the date a year from today? Write month date, year format\",\n",
    "    \"current_date\": date.today()\n",
    "})"
   ],
   "id": "104ca50da07bd6a2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'June 14, 2025'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T14:24:41.843133Z",
     "start_time": "2024-06-14T14:24:38.245157Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SOURCE = \"\"\"\n",
    "Old Ship Saloon 2023 quarterly revenue numbers:\n",
    "Q1: $174782.38\n",
    "Q2: $467372.38\n",
    "Q3: $474773.38\n",
    "Q4: $389289.23\n",
    "\"\"\"\n",
    "\n",
    "rag_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", 'Use this for context\\n {context}'),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "rag_chain = rag_template | chat_model | StrOutputParser()\n",
    "\n",
    "rag_chain.invoke({\n",
    "    \"question\": \"What was the Old Ship Saloon's total revenue in Q1 2023?\",\n",
    "    \"context\": SOURCE\n",
    "})"
   ],
   "id": "6440c48127ec90ad",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Old Ship Saloon's total revenue in Q1 2023 was $174782.38.\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T14:25:50.989932Z",
     "start_time": "2024-06-14T14:25:21.600700Z"
    }
   },
   "cell_type": "code",
   "source": "%pip install langchain",
   "id": "3cd0bfdcc374985e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\r\n",
      "  Downloading langchain-0.2.4-py3-none-any.whl.metadata (7.0 kB)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from langchain) (6.0.1)\r\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\r\n",
      "  Downloading SQLAlchemy-2.0.30-cp312-cp312-macosx_10_9_x86_64.whl.metadata (9.6 kB)\r\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\r\n",
      "  Downloading aiohttp-3.9.5-cp312-cp312-macosx_10_9_x86_64.whl.metadata (7.5 kB)\r\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.6 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from langchain) (0.2.6)\r\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\r\n",
      "  Downloading langchain_text_splitters-0.2.1-py3-none-any.whl.metadata (2.2 kB)\r\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from langchain) (0.1.77)\r\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from langchain) (1.26.4)\r\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from langchain) (2.7.4)\r\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from langchain) (2.31.0)\r\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from langchain) (8.3.0)\r\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\r\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\r\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\r\n",
      "  Downloading frozenlist-1.4.1-cp312-cp312-macosx_10_9_x86_64.whl.metadata (12 kB)\r\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\r\n",
      "  Downloading multidict-6.0.5-cp312-cp312-macosx_10_9_x86_64.whl.metadata (4.2 kB)\r\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\r\n",
      "  Downloading yarl-1.9.4-cp312-cp312-macosx_10_9_x86_64.whl.metadata (31 kB)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from langchain-core<0.3.0,>=0.2.6->langchain) (1.33)\r\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from langchain-core<0.3.0,>=0.2.6->langchain) (23.2)\r\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.5)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from pydantic<3,>=1->langchain) (2.18.4)\r\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from pydantic<3,>=1->langchain) (4.11.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.1.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2024.6.2)\r\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\r\n",
      "  Downloading greenlet-3.0.3.tar.gz (182 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m182.0/182.0 kB\u001B[0m \u001B[31m4.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25h  Installing build dependencies ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Getting requirements to build wheel ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Installing backend dependencies ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Preparing metadata (pyproject.toml) ... \u001B[?25ldone\r\n",
      "\u001B[?25hRequirement already satisfied: jsonpointer>=1.9 in /Users/teenageorge/miniconda3/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.6->langchain) (2.1)\r\n",
      "Downloading langchain-0.2.4-py3-none-any.whl (974 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m974.2/974.2 kB\u001B[0m \u001B[31m11.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading aiohttp-3.9.5-cp312-cp312-macosx_10_9_x86_64.whl (395 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m396.0/396.0 kB\u001B[0m \u001B[31m10.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading langchain_text_splitters-0.2.1-py3-none-any.whl (23 kB)\r\n",
      "Downloading SQLAlchemy-2.0.30-cp312-cp312-macosx_10_9_x86_64.whl (2.1 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.1/2.1 MB\u001B[0m \u001B[31m20.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\r\n",
      "Downloading frozenlist-1.4.1-cp312-cp312-macosx_10_9_x86_64.whl (53 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m53.7/53.7 kB\u001B[0m \u001B[31m1.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading multidict-6.0.5-cp312-cp312-macosx_10_9_x86_64.whl (29 kB)\r\n",
      "Downloading yarl-1.9.4-cp312-cp312-macosx_10_9_x86_64.whl (81 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m81.6/81.6 kB\u001B[0m \u001B[31m2.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hBuilding wheels for collected packages: greenlet\r\n",
      "  Building wheel for greenlet (pyproject.toml) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for greenlet: filename=greenlet-3.0.3-cp312-cp312-macosx_10_9_x86_64.whl size=215159 sha256=c2764c65af7a592d1305e31c885f292eb69d98f70d793fc97b48254a9dc6c23b\r\n",
      "  Stored in directory: /Users/teenageorge/Library/Caches/pip/wheels/83/96/fd/f13a9a496711b39256f0af202a7123981f868a36f7ef8d8e9c\r\n",
      "Successfully built greenlet\r\n",
      "Installing collected packages: multidict, greenlet, frozenlist, yarl, SQLAlchemy, aiosignal, aiohttp, langchain-text-splitters, langchain\r\n",
      "Successfully installed SQLAlchemy-2.0.30 aiohttp-3.9.5 aiosignal-1.3.1 frozenlist-1.4.1 greenlet-3.0.3 langchain-0.2.4 langchain-text-splitters-0.2.1 multidict-6.0.5 yarl-1.9.4\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T14:28:56.169382Z",
     "start_time": "2024-06-14T14:28:54.218370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.globals import set_debug\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "set_debug(True)\n",
    "\n",
    "from datetime import date\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", 'You know that current date is \"{current_date}\"'),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "chain = prompt | chat_model | StrOutputParser()\n",
    "\n",
    "chain.invoke({\n",
    "    \"question\": \"What is today's date?\",\n",
    "    \"current_date\": date.today()\n",
    "})"
   ],
   "id": "5dbea8ea7bbab73f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You know that current date is \\\"2024-06-14\\\"\\nHuman: What is today's date?\"\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[chain:RunnableSequence > llm:ChatOpenAI] [1.92s] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Today's date is June 14, 2024.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Today's date is June 14, 2024.\",\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 12,\n",
      "                \"prompt_tokens\": 31,\n",
      "                \"total_tokens\": 43\n",
      "              },\n",
      "              \"model_name\": \"gpt-4\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-c91dd978-040b-402d-b985-d0989528b25f-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 31,\n",
      "              \"output_tokens\": 12,\n",
      "              \"total_tokens\": 43\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 12,\n",
      "      \"prompt_tokens\": 31,\n",
      "      \"total_tokens\": 43\n",
      "    },\n",
      "    \"model_name\": \"gpt-4\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"Today's date is June 14, 2024.\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:RunnableSequence] [1.93s] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"Today's date is June 14, 2024.\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Today's date is June 14, 2024.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T14:31:22.729508Z",
     "start_time": "2024-06-14T14:31:20.193850Z"
    }
   },
   "cell_type": "code",
   "source": [
    "set_debug(False)\n",
    "\n",
    "stream = chain.astream_events({\n",
    "    \"question\": \"What is today's date?\",\n",
    "    \"current_date\": date.today()\n",
    "}, version=\"v1\")\n",
    "\n",
    "async for event in stream:\n",
    "    print(event)\n",
    "    print(\"-------\")"
   ],
   "id": "9717deb53a520100",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/teenageorge/miniconda3/lib/python3.12/site-packages/langchain_core/_api/beta_decorator.py:87: LangChainBetaWarning: This API is in beta and may change in the future.\n",
      "  warn_beta(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'on_chain_start', 'run_id': '94ea0653-b144-4206-b618-d5c411d82fea', 'name': 'RunnableSequence', 'tags': [], 'metadata': {}, 'data': {'input': {'question': \"What is today's date?\", 'current_date': datetime.date(2024, 6, 14)}}, 'parent_ids': []}\n",
      "-------\n",
      "{'event': 'on_prompt_start', 'name': 'ChatPromptTemplate', 'run_id': 'b4089499-a4b8-4fff-b42f-9cb0eec9af53', 'tags': ['seq:step:1'], 'metadata': {}, 'data': {'input': {'question': \"What is today's date?\", 'current_date': datetime.date(2024, 6, 14)}}, 'parent_ids': []}\n",
      "-------\n",
      "{'event': 'on_prompt_end', 'name': 'ChatPromptTemplate', 'run_id': 'b4089499-a4b8-4fff-b42f-9cb0eec9af53', 'tags': ['seq:step:1'], 'metadata': {}, 'data': {'input': {'question': \"What is today's date?\", 'current_date': datetime.date(2024, 6, 14)}, 'output': ChatPromptValue(messages=[SystemMessage(content='You know that current date is \"2024-06-14\"'), HumanMessage(content=\"What is today's date?\")])}, 'parent_ids': []}\n",
      "-------\n",
      "{'event': 'on_chat_model_start', 'name': 'ChatOpenAI', 'run_id': '63e17161-ab14-4ac0-8772-510a289c608a', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-4', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'data': {'input': {'messages': [[SystemMessage(content='You know that current date is \"2024-06-14\"'), HumanMessage(content=\"What is today's date?\")]]}}, 'parent_ids': []}\n",
      "-------\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '63e17161-ab14-4ac0-8772-510a289c608a', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-4', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'data': {'chunk': AIMessageChunk(content='', id='run-63e17161-ab14-4ac0-8772-510a289c608a')}, 'parent_ids': []}\n",
      "-------\n",
      "{'event': 'on_parser_start', 'name': 'StrOutputParser', 'run_id': '68e5e361-aa6c-4ed8-ab87-ce72b7f2f5d5', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {}, 'parent_ids': []}\n",
      "-------\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '68e5e361-aa6c-4ed8-ab87-ce72b7f2f5d5', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ''}, 'parent_ids': []}\n",
      "-------\n",
      "{'event': 'on_chain_stream', 'run_id': '94ea0653-b144-4206-b618-d5c411d82fea', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ''}, 'parent_ids': []}\n",
      "-------\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '63e17161-ab14-4ac0-8772-510a289c608a', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-4', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'data': {'chunk': AIMessageChunk(content='Today', id='run-63e17161-ab14-4ac0-8772-510a289c608a')}, 'parent_ids': []}\n",
      "-------\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '68e5e361-aa6c-4ed8-ab87-ce72b7f2f5d5', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': 'Today'}, 'parent_ids': []}\n",
      "-------\n",
      "{'event': 'on_chain_stream', 'run_id': '94ea0653-b144-4206-b618-d5c411d82fea', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': 'Today'}, 'parent_ids': []}\n",
      "-------\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '63e17161-ab14-4ac0-8772-510a289c608a', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-4', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'data': {'chunk': AIMessageChunk(content=\"'s\", id='run-63e17161-ab14-4ac0-8772-510a289c608a')}, 'parent_ids': []}\n",
      "-------\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '68e5e361-aa6c-4ed8-ab87-ce72b7f2f5d5', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': \"'s\"}, 'parent_ids': []}\n",
      "-------\n",
      "{'event': 'on_chain_stream', 'run_id': '94ea0653-b144-4206-b618-d5c411d82fea', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': \"'s\"}, 'parent_ids': []}\n",
      "-------\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '63e17161-ab14-4ac0-8772-510a289c608a', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-4', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'data': {'chunk': AIMessageChunk(content=' date', id='run-63e17161-ab14-4ac0-8772-510a289c608a')}, 'parent_ids': []}\n",
      "-------\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '68e5e361-aa6c-4ed8-ab87-ce72b7f2f5d5', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' date'}, 'parent_ids': []}\n",
      "-------\n",
      "{'event': 'on_chain_stream', 'run_id': '94ea0653-b144-4206-b618-d5c411d82fea', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' date'}, 'parent_ids': []}\n",
      "-------\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '63e17161-ab14-4ac0-8772-510a289c608a', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-4', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'data': {'chunk': AIMessageChunk(content=' is', id='run-63e17161-ab14-4ac0-8772-510a289c608a')}, 'parent_ids': []}\n",
      "-------\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '68e5e361-aa6c-4ed8-ab87-ce72b7f2f5d5', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' is'}, 'parent_ids': []}\n",
      "-------\n",
      "{'event': 'on_chain_stream', 'run_id': '94ea0653-b144-4206-b618-d5c411d82fea', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' is'}, 'parent_ids': []}\n",
      "-------\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '63e17161-ab14-4ac0-8772-510a289c608a', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-4', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'data': {'chunk': AIMessageChunk(content=' June', id='run-63e17161-ab14-4ac0-8772-510a289c608a')}, 'parent_ids': []}\n",
      "-------\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '68e5e361-aa6c-4ed8-ab87-ce72b7f2f5d5', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' June'}, 'parent_ids': []}\n",
      "-------\n",
      "{'event': 'on_chain_stream', 'run_id': '94ea0653-b144-4206-b618-d5c411d82fea', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' June'}, 'parent_ids': []}\n",
      "-------\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '63e17161-ab14-4ac0-8772-510a289c608a', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-4', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'data': {'chunk': AIMessageChunk(content=' ', id='run-63e17161-ab14-4ac0-8772-510a289c608a')}, 'parent_ids': []}\n",
      "-------\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '68e5e361-aa6c-4ed8-ab87-ce72b7f2f5d5', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' '}, 'parent_ids': []}\n",
      "-------\n",
      "{'event': 'on_chain_stream', 'run_id': '94ea0653-b144-4206-b618-d5c411d82fea', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' '}, 'parent_ids': []}\n",
      "-------\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '63e17161-ab14-4ac0-8772-510a289c608a', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-4', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'data': {'chunk': AIMessageChunk(content='14', id='run-63e17161-ab14-4ac0-8772-510a289c608a')}, 'parent_ids': []}\n",
      "-------\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '68e5e361-aa6c-4ed8-ab87-ce72b7f2f5d5', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': '14'}, 'parent_ids': []}\n",
      "-------\n",
      "{'event': 'on_chain_stream', 'run_id': '94ea0653-b144-4206-b618-d5c411d82fea', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': '14'}, 'parent_ids': []}\n",
      "-------\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '63e17161-ab14-4ac0-8772-510a289c608a', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-4', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'data': {'chunk': AIMessageChunk(content=',', id='run-63e17161-ab14-4ac0-8772-510a289c608a')}, 'parent_ids': []}\n",
      "-------\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '68e5e361-aa6c-4ed8-ab87-ce72b7f2f5d5', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ','}, 'parent_ids': []}\n",
      "-------\n",
      "{'event': 'on_chain_stream', 'run_id': '94ea0653-b144-4206-b618-d5c411d82fea', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ','}, 'parent_ids': []}\n",
      "-------\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '63e17161-ab14-4ac0-8772-510a289c608a', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-4', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'data': {'chunk': AIMessageChunk(content=' ', id='run-63e17161-ab14-4ac0-8772-510a289c608a')}, 'parent_ids': []}\n",
      "-------\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '68e5e361-aa6c-4ed8-ab87-ce72b7f2f5d5', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' '}, 'parent_ids': []}\n",
      "-------\n",
      "{'event': 'on_chain_stream', 'run_id': '94ea0653-b144-4206-b618-d5c411d82fea', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' '}, 'parent_ids': []}\n",
      "-------\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '63e17161-ab14-4ac0-8772-510a289c608a', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-4', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'data': {'chunk': AIMessageChunk(content='202', id='run-63e17161-ab14-4ac0-8772-510a289c608a')}, 'parent_ids': []}\n",
      "-------\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '68e5e361-aa6c-4ed8-ab87-ce72b7f2f5d5', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': '202'}, 'parent_ids': []}\n",
      "-------\n",
      "{'event': 'on_chain_stream', 'run_id': '94ea0653-b144-4206-b618-d5c411d82fea', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': '202'}, 'parent_ids': []}\n",
      "-------\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '63e17161-ab14-4ac0-8772-510a289c608a', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-4', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'data': {'chunk': AIMessageChunk(content='4', id='run-63e17161-ab14-4ac0-8772-510a289c608a')}, 'parent_ids': []}\n",
      "-------\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '68e5e361-aa6c-4ed8-ab87-ce72b7f2f5d5', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': '4'}, 'parent_ids': []}\n",
      "-------\n",
      "{'event': 'on_chain_stream', 'run_id': '94ea0653-b144-4206-b618-d5c411d82fea', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': '4'}, 'parent_ids': []}\n",
      "-------\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '63e17161-ab14-4ac0-8772-510a289c608a', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-4', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'data': {'chunk': AIMessageChunk(content='.', id='run-63e17161-ab14-4ac0-8772-510a289c608a')}, 'parent_ids': []}\n",
      "-------\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '68e5e361-aa6c-4ed8-ab87-ce72b7f2f5d5', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': '.'}, 'parent_ids': []}\n",
      "-------\n",
      "{'event': 'on_chain_stream', 'run_id': '94ea0653-b144-4206-b618-d5c411d82fea', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': '.'}, 'parent_ids': []}\n",
      "-------\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '63e17161-ab14-4ac0-8772-510a289c608a', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-4', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'data': {'chunk': AIMessageChunk(content='', response_metadata={'finish_reason': 'stop'}, id='run-63e17161-ab14-4ac0-8772-510a289c608a')}, 'parent_ids': []}\n",
      "-------\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '68e5e361-aa6c-4ed8-ab87-ce72b7f2f5d5', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ''}, 'parent_ids': []}\n",
      "-------\n",
      "{'event': 'on_chain_stream', 'run_id': '94ea0653-b144-4206-b618-d5c411d82fea', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ''}, 'parent_ids': []}\n",
      "-------\n",
      "{'event': 'on_chat_model_end', 'name': 'ChatOpenAI', 'run_id': '63e17161-ab14-4ac0-8772-510a289c608a', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-4', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'data': {'input': {'messages': [[SystemMessage(content='You know that current date is \"2024-06-14\"'), HumanMessage(content=\"What is today's date?\")]]}, 'output': {'generations': [[{'text': \"Today's date is June 14, 2024.\", 'generation_info': {'finish_reason': 'stop'}, 'type': 'ChatGenerationChunk', 'message': AIMessageChunk(content=\"Today's date is June 14, 2024.\", response_metadata={'finish_reason': 'stop'}, id='run-63e17161-ab14-4ac0-8772-510a289c608a')}]], 'llm_output': None, 'run': None}}, 'parent_ids': []}\n",
      "-------\n",
      "{'event': 'on_parser_end', 'name': 'StrOutputParser', 'run_id': '68e5e361-aa6c-4ed8-ab87-ce72b7f2f5d5', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'input': AIMessageChunk(content=\"Today's date is June 14, 2024.\", response_metadata={'finish_reason': 'stop'}, id='run-63e17161-ab14-4ac0-8772-510a289c608a'), 'output': \"Today's date is June 14, 2024.\"}, 'parent_ids': []}\n",
      "-------\n",
      "{'event': 'on_chain_end', 'name': 'RunnableSequence', 'run_id': '94ea0653-b144-4206-b618-d5c411d82fea', 'tags': [], 'metadata': {}, 'data': {'output': \"Today's date is June 14, 2024.\"}, 'parent_ids': []}\n",
      "-------\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ba467d3baa57e17f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
